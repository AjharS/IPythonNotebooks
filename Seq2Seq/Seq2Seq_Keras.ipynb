{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# link1: https://www.tensorflow.org/tutorials/seq2seq\n",
    "# link2: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class SentenceToCharVecEncoder:\n",
    "    def __init__(self, dictionary):\n",
    "        self.dictionary = dictionary\n",
    "        numchars = len(self.dictionary)\n",
    "        self.onehot_encoder = OneHotEncoder()\n",
    "        self.onehot_encoder.fit(np.arange(numchars).reshape((numchars, 1)))\n",
    "        \n",
    "    def encode_sentence(self, sent):\n",
    "        return self.onehot_encoder.transform(\n",
    "            np.array([self.dictionary.token2id[c] for c in sent]).reshape((len(sent), 1))\n",
    "        )\n",
    "    \n",
    "    def encode_sentences(self, sentences, sparse=True):\n",
    "        if sparse:\n",
    "            return map(lambda sent: self.encode_sentence(sent), sentences)\n",
    "        else:\n",
    "            return map(lambda sent: self.encode_sentence(sent).toarray(), sentences)\n",
    "    \n",
    "def initSentenceToCharVecEncoder(textfile):\n",
    "    text = filter(lambda t: len(t)>0, [t.strip() for t in textfile])\n",
    "    dictionary = Dictionary(map(lambda line: [c for c in line], text))\n",
    "    return SentenceToCharVecEncoder(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "sent_encoder = initSentenceToCharVecEncoder(urllib2.urlopen('http://norvig.com/big.txt', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x92 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_encoder.encode_sentence('abAtrE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<11x92 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 11 stored elements in Compressed Sparse Row format>,\n",
       " <22x92 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 22 stored elements in Compressed Sparse Row format>,\n",
       " <14x92 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 14 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_encoder.encode_sentences(['I love you.', 'seq2seq model in Keras', 'language model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_encoder.encode_sentences(['I love you.', 'seq2seq model in Keras', 'language model'], sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "numchars = len(sent_encoder.dictionary)\n",
    "latent_dim = numchars + 20\n",
    "\n",
    "print numchars\n",
    "print latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textfile = urllib2.urlopen('http://norvig.com/big.txt', 'r')\n",
    "text = filter(lambda t: len(t)>0, [t.strip() for t in textfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, numchars))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, numchars))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(numchars, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chartovec_encoder = initSentenceToCharVecEncoder(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_input = chartovec_encoder.encode_sentences(text[:-1])\n",
    "decoder_input = chartovec_encoder.encode_sentences(text[1:])\n",
    "decoder_output = chartovec_encoder.encode_sentences(text[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103500\n",
      "[(64, 92), (25, 92), (45, 92), (68, 92), (68, 92), (42, 92), (68, 92), (68, 92), (34, 92), (68, 92), (68, 92), (68, 92), (68, 92), (55, 92), (63, 92), (63, 92), (64, 92), (40, 92), (30, 92), (40, 92), (42, 92), (11, 92), (17, 92), (29, 92), (79, 92), (37, 92), (17, 92), (15, 92), (2, 92), (22, 92), (8, 92), (23, 92), (25, 92), (23, 92), (31, 92), (23, 92), (32, 92), (40, 92), (40, 92), (41, 92), (38, 92), (38, 92), (40, 92), (35, 92), (2, 92), (1146, 92), (1300, 92), (978, 92), (337, 92), (114, 92), (20, 92), (175, 92), (24, 92), (150, 92), (394, 92), (67, 92), (820, 92), (383, 92), (241, 92), (13, 92), (12, 92), (31, 92), (26, 92), (25, 92), (489, 92), (62, 92), (492, 92), (76, 92), (217, 92), (74, 92), (208, 92), (109, 92), (124, 92), (41, 92), (59, 92), (649, 92), (40, 92), (491, 92), (146, 92), (228, 92), (39, 92), (138, 92), (19, 92), (137, 92), (161, 92), (23, 92), (1126, 92), (193, 92), (170, 92), (270, 92), (183, 92), (298, 92), (25, 92), (8, 92), (232, 92), (39, 92), (293, 92), (104, 92), (273, 92), (108, 92)]\n"
     ]
    }
   ],
   "source": [
    "print(len(encoder_input))\n",
    "print(map(lambda e: e.shape, encoder_input[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103500\n",
      "[(25, 92), (45, 92), (68, 92), (68, 92), (42, 92), (68, 92), (68, 92), (34, 92), (68, 92), (68, 92), (68, 92), (68, 92), (55, 92), (63, 92), (63, 92), (64, 92), (40, 92), (30, 92), (40, 92), (42, 92), (11, 92), (17, 92), (29, 92), (79, 92), (37, 92), (17, 92), (15, 92), (2, 92), (22, 92), (8, 92), (23, 92), (25, 92), (23, 92), (31, 92), (23, 92), (32, 92), (40, 92), (40, 92), (41, 92), (38, 92), (38, 92), (40, 92), (35, 92), (2, 92), (1146, 92), (1300, 92), (978, 92), (337, 92), (114, 92), (20, 92), (175, 92), (24, 92), (150, 92), (394, 92), (67, 92), (820, 92), (383, 92), (241, 92), (13, 92), (12, 92), (31, 92), (26, 92), (25, 92), (489, 92), (62, 92), (492, 92), (76, 92), (217, 92), (74, 92), (208, 92), (109, 92), (124, 92), (41, 92), (59, 92), (649, 92), (40, 92), (491, 92), (146, 92), (228, 92), (39, 92), (138, 92), (19, 92), (137, 92), (161, 92), (23, 92), (1126, 92), (193, 92), (170, 92), (270, 92), (183, 92), (298, 92), (25, 92), (8, 92), (232, 92), (39, 92), (293, 92), (104, 92), (273, 92), (108, 92), (268, 92)]\n"
     ]
    }
   ],
   "source": [
    "print(len(decoder_input))\n",
    "print(map(lambda e: e.shape, decoder_input[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103500\n",
      "[(25, 92), (45, 92), (68, 92), (68, 92), (42, 92), (68, 92), (68, 92), (34, 92), (68, 92), (68, 92), (68, 92), (68, 92), (55, 92), (63, 92), (63, 92), (64, 92), (40, 92), (30, 92), (40, 92), (42, 92), (11, 92), (17, 92), (29, 92), (79, 92), (37, 92), (17, 92), (15, 92), (2, 92), (22, 92), (8, 92), (23, 92), (25, 92), (23, 92), (31, 92), (23, 92), (32, 92), (40, 92), (40, 92), (41, 92), (38, 92), (38, 92), (40, 92), (35, 92), (2, 92), (1146, 92), (1300, 92), (978, 92), (337, 92), (114, 92), (20, 92), (175, 92), (24, 92), (150, 92), (394, 92), (67, 92), (820, 92), (383, 92), (241, 92), (13, 92), (12, 92), (31, 92), (26, 92), (25, 92), (489, 92), (62, 92), (492, 92), (76, 92), (217, 92), (74, 92), (208, 92), (109, 92), (124, 92), (41, 92), (59, 92), (649, 92), (40, 92), (491, 92), (146, 92), (228, 92), (39, 92), (138, 92), (19, 92), (137, 92), (161, 92), (23, 92), (1126, 92), (193, 92), (170, 92), (270, 92), (183, 92), (298, 92), (25, 92), (8, 92), (232, 92), (39, 92), (293, 92), (104, 92), (273, 92), (108, 92), (268, 92)]\n"
     ]
    }
   ],
   "source": [
    "print(len(decoder_output))\n",
    "print(map(lambda e: e.shape, decoder_output[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
