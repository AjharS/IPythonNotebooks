{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.tokenize.moses import MosesDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileids = inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detokenizer = MosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addresses = [' '.join(map(lambda sent: detokenizer.detokenize(sent, return_str=True), inaugural.sents(fileid))) \n",
    "             for fileid in fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1789-Washington.txt',\n",
       " u'1793-Washington.txt',\n",
       " u'1797-Adams.txt',\n",
       " u'1801-Jefferson.txt',\n",
       " u'1805-Jefferson.txt',\n",
       " u'1809-Madison.txt',\n",
       " u'1813-Madison.txt',\n",
       " u'1817-Monroe.txt',\n",
       " u'1821-Monroe.txt',\n",
       " u'1825-Adams.txt',\n",
       " u'1829-Jackson.txt',\n",
       " u'1833-Jackson.txt',\n",
       " u'1837-VanBuren.txt',\n",
       " u'1841-Harrison.txt',\n",
       " u'1845-Polk.txt',\n",
       " u'1849-Taylor.txt',\n",
       " u'1853-Pierce.txt',\n",
       " u'1857-Buchanan.txt',\n",
       " u'1861-Lincoln.txt',\n",
       " u'1865-Lincoln.txt',\n",
       " u'1869-Grant.txt',\n",
       " u'1873-Grant.txt',\n",
       " u'1877-Hayes.txt',\n",
       " u'1881-Garfield.txt',\n",
       " u'1885-Cleveland.txt',\n",
       " u'1889-Harrison.txt',\n",
       " u'1893-Cleveland.txt',\n",
       " u'1897-McKinley.txt',\n",
       " u'1901-McKinley.txt',\n",
       " u'1905-Roosevelt.txt',\n",
       " u'1909-Taft.txt',\n",
       " u'1913-Wilson.txt',\n",
       " u'1917-Wilson.txt',\n",
       " u'1921-Harding.txt',\n",
       " u'1925-Coolidge.txt',\n",
       " u'1929-Hoover.txt',\n",
       " u'1933-Roosevelt.txt',\n",
       " u'1937-Roosevelt.txt',\n",
       " u'1941-Roosevelt.txt',\n",
       " u'1945-Roosevelt.txt',\n",
       " u'1949-Truman.txt',\n",
       " u'1953-Eisenhower.txt',\n",
       " u'1957-Eisenhower.txt',\n",
       " u'1961-Kennedy.txt',\n",
       " u'1965-Johnson.txt',\n",
       " u'1969-Nixon.txt',\n",
       " u'1973-Nixon.txt',\n",
       " u'1977-Carter.txt',\n",
       " u'1981-Reagan.txt',\n",
       " u'1985-Reagan.txt',\n",
       " u'1989-Bush.txt',\n",
       " u'1993-Clinton.txt',\n",
       " u'1997-Clinton.txt',\n",
       " u'2001-Bush.txt',\n",
       " u'2005-Bush.txt',\n",
       " u'2009-Obama.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using seq2seq, need to fetch from: https://github.com/bstriner/keras-seq2seq\n",
    "import kerasseq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_charset(words):\n",
    "    \"\"\"\n",
    "    List unique characters\n",
    "    :param words:\n",
    "    :return: list of characters, dictionary from characters to indexes\n",
    "    \"\"\"\n",
    "    charset = list(set(itertools.chain.from_iterable(words)))\n",
    "    charset.sort()\n",
    "    charmap = {c: i for i, c in enumerate(charset)}\n",
    "    return charset, charmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_word(word, charmap):\n",
    "    \"\"\"\n",
    "    Convert string to list of indexes into charset\n",
    "    :param word:\n",
    "    :param charmap:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return [charmap[c] for c in word]\n",
    "\n",
    "def map_words(words, charmap):\n",
    "    return [map_word(w, charmap) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    \"\"\"\n",
    "    Remove non-asci characters and downcase\n",
    "    :param word:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return \"\".join([c for c in word.lower() if ord(c) < 128])\n",
    "\n",
    "\n",
    "def clean_words(words):\n",
    "    \"\"\"\n",
    "    Remove words < 3 characters\n",
    "    :param words:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return [clean_word(w) for w in words if len(clean_word(w)) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from kerasseq2seq.s2s_loss import s2sloss\n",
    "from kerasseq2seq.s2s_layer import S2SLayer\n",
    "from kerasseq2seq.s2s_data import process_sequences, process_test_sequences, one_hot_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"tuple\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-44d07df287f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0ms2s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS2SLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# output of layer is softmax and prediction concatenated; slice the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mysoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/layers/recurrent.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'initial_state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/layers/recurrent.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, initial_state, training)\u001b[0m\n\u001b[1;32m    301\u001b[0m                                              \u001b[0mconstants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                                              input_length=input_shape[1])\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2290\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2291\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2292\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"tuple\") to list"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_dim = 512\n",
    "batch_size = 128\n",
    "steps_per_epoch = 512\n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "\n",
    "# Load and clean data\n",
    "words = clean_words(addresses)\n",
    "charset, charmap = get_charset(words)\n",
    "x_k = len(charset)\n",
    "vectors = map_words(words, charmap)\n",
    "max_word = max(len(w) for w in vectors)\n",
    "depth = max_word * 2 + 4\n",
    "\n",
    "# Create model\n",
    "x = Input((None, 3), dtype='float32')\n",
    "s2s = S2SLayer(x_k, hidden_dim, stochastic=True)\n",
    "# output of layer is softmax and prediction concatenated; slice the output\n",
    "y = s2s(x)\n",
    "ysoftmax = Lambda(lambda z: z[:, :, :-1], output_shape=lambda z: (z[0], z[1], z[2] - 1))(y)\n",
    "ypred = Lambda(lambda z: z[:, :, -1], output_shape=lambda z: (z[0], z[1], 1))(y)\n",
    "# model for training\n",
    "m = Model(inputs=[x], outputs=[ysoftmax])\n",
    "m.summary()\n",
    "m.compile(Adam(lr), s2sloss(x[:, :, 1]))\n",
    "# model for testing\n",
    "mtest = Model(inputs=[x], outputs=[ypred])\n",
    "# callback to print results\n",
    "cb = LambdaCallback(on_epoch_end=on_epoch_end(mtest, vectors, charset, depth))\n",
    "# train model\n",
    "m.fit_generator(bigram_generator(vectors, batch_size, x_k), callbacks=[cb],\n",
    "                steps_per_epoch=steps_per_epoch, epochs=epochs,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfd'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_word('dfd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}